{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dYi-RmFsgAp"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.7.0\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAbtbpcUsvVB"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-quantum==0.6.0 --use-deprecated=legacy-resolver\n",
        "from IPython.display import clear_output  \n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62UGKVVjtDWZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import sympy as sp\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq\n",
        "from cirq.contrib.svg import SVGCircuit\n",
        "from h5py import File as HDF5File\n",
        "from PIL import Image\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.colors import LogNorm, Normalize\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VVhG-MYtFZW",
        "outputId": "e7f0eef5-3e1a-43b9-f60c-d01a9cd216ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-58i86ftwRl"
      },
      "outputs": [],
      "source": [
        "jet_mass_datafile = '/content/gdrive/MyDrive//jet-images_Mass60-100_pT250-300_R1.25_Pix25.hdf5'\n",
        "jet_mass_data = HDF5File(jet_mass_datafile, 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aIIZmxTt17C",
        "outputId": "72f50a31-65aa-4f8c-ba7d-e93e2c2a1917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<KeysViewHDF5 ['image', 'jet_delta_R', 'jet_eta', 'jet_mass', 'jet_phi', 'jet_pt', 'signal', 'tau_1', 'tau_2', 'tau_21', 'tau_3', 'tau_32']>\n"
          ]
        }
      ],
      "source": [
        "print(jet_mass_data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "MbmyK6b8t5jP",
        "outputId": "730359d6-8bd4-466d-865d-fb289df5b6c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(872666, 25, 25)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff0b148ead0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "X_jet = jet_mass_data['image']\n",
        "print(X_jet.shape)\n",
        "plt.imshow(X_jet[5,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYq0GS8Et5X7",
        "outputId": "9cf60e6d-311e-44b0-d8d9-b1b6d086a30b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum pixel value for Jet mass images: 312\n",
            "(1500, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "max_val_pix = np.argmax(np.mean(X_jet[:, :, :], axis=0))\n",
        "print(\"Maximum pixel value for Jet mass images:\",max_val_pix)\n",
        "center = [int(max_val_pix/25), max_val_pix%25]\n",
        "\n",
        "img_size = 8\n",
        "X_jet = X_jet[:1500, (center[0]-int(img_size/2)):(center[0]+int(img_size/2)), (center[1]-int(img_size/2)):(center[1]+int(img_size/2))]\n",
        "\n",
        "print(X_jet.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8uFnSgyuBYo"
      },
      "outputs": [],
      "source": [
        "def plot_jet_image(content,\n",
        "#                     output_name,\n",
        "                    vmin=1e-6,\n",
        "                    vmax=300,\n",
        "                    title=''):\n",
        "    '''\n",
        "    Function to help you visualize a jet image on a log scale\n",
        "    Args:\n",
        "    -----\n",
        "       content : numpy array of dimensions 25x25, first arg to imshow, content of the image\n",
        "                 e.g.: generated_images.mean(axis=0) --> the average generated image\n",
        "                       real_images.mean(axis=0) --> the average Pythia image\n",
        "                       generated_images[aux_out == 1].mean(axis=0) --> the average generated image labeled as real by the discriminator \n",
        "                       etc...\n",
        "       output_name : string, name of the output file where the plot will be saved. Note: it will be located in ../plots/\n",
        "       vmin : (default = 1e-6) float, lower bound of the pixel intensity scale before saturation\n",
        "       vmax : (default = 300) float, upper bound of the pixel intensity scale before saturation\n",
        "       title : (default = '') string, title of the plot, to be displayed on top of the image\n",
        "    Outputs:\n",
        "    --------\n",
        "       no function returns\n",
        "       saves file in ../plots/output_name\n",
        "    '''\n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    extent=[-1.25, 1.25, -1.25, 1.25]\n",
        "    im = ax.imshow(content, interpolation='nearest', norm=LogNorm(vmin=vmin, vmax=vmax), extent=extent)\n",
        "    cbar = plt.colorbar(im, fraction=0.05, pad=0.05)\n",
        "    cbar.set_label(r'Pixel $p_T$ (GeV)', y=0.85)\n",
        "    plt.xlabel(r'[Transformed] Pseudorapidity $(\\eta)$')\n",
        "    plt.ylabel(r'[Transformed] Azimuthal Angle $(\\phi)$')\n",
        "    plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "k_OIGqmfuIBi",
        "outputId": "8334e31b-b869-4808-99d3-cc324f7cca18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcb7c249590>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(X_jet[5,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo_82vRguN9x"
      },
      "outputs": [],
      "source": [
        "def one_qubit_unitary(qubit, symbols):\n",
        "  return cirq.Circuit(\n",
        "    [#cirq.rx(symbols[0])(qubit),\n",
        "      cirq.rz(symbols[0])(qubit),\n",
        "      cirq.ry(symbols[1])(qubit),\n",
        "      cirq.rz(symbols[2])(qubit)]\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_cd9-s6uSUS"
      },
      "outputs": [],
      "source": [
        "def two_qubit_unitary(qubits):\n",
        "  # cx_ops = [cirq.CX(q0, q1) for q0, q1 in zip(qubits, qubits[1:])]\n",
        "  # cx_ops += ([cirq.CX(qubits[-1], qubits[0])] if len(qubits) != 2 else [])\n",
        "  cx_ops=[]\n",
        "  for i in range(0,len(qubits),2):\n",
        "    if(i+1 <= len(qubits)-1):\n",
        "      cx_ops += [cirq.CX(qubits[i],qubits[i+1])]\n",
        "  for i in range(1,len(qubits),2):\n",
        "    if(i+1 <= len(qubits)-1):\n",
        "      cx_ops += [cirq.CX(qubits[i],qubits[i+1])]\n",
        "  return cx_ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keOI1sMMuUy3"
      },
      "outputs": [],
      "source": [
        "def pqc_circuit_for_conv(qubits,layers):\n",
        "  circuit = cirq.Circuit()\n",
        "  num_qubits = len(qubits)\n",
        "  input_symbols = sp.symbols('x_:'+str(num_qubits))\n",
        "  param_symbols = sp.symbols('theta_:'+str(3*num_qubits*layers))\n",
        "  param_symbols = np.reshape(param_symbols,(layers,num_qubits,3))\n",
        "  for i in range(num_qubits):\n",
        "    circuit += cirq.ry(input_symbols[i])(qubits[i])\n",
        "  \n",
        "  for layer in range(layers):\n",
        "    for i,q in enumerate(qubits):\n",
        "      circuit += one_qubit_unitary(q,param_symbols[layer,i,:])\n",
        "    circuit += two_qubit_unitary(qubits)\n",
        "  \n",
        "  return circuit,input_symbols,list(param_symbols.flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "BMD63zltudaL",
        "outputId": "ac646f48-7b49-4b36-a2b4-ef55ad0dcf49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7ff0aabffd50>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"3156.3230859375008\" height=\"200.0\"><line x1=\"34.7588671875\" x2=\"3126.3230859375008\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"3126.3230859375008\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"3126.3230859375008\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"3126.3230859375008\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"854.06779296875\" x2=\"854.06779296875\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1498.2754296875003\" x2=\"1498.2754296875003\" y1=\"125.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1558.2754296875003\" x2=\"1558.2754296875003\" y1=\"75.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2350.94015625\" x2=\"2350.94015625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3026.3230859375008\" x2=\"3026.3230859375008\" y1=\"125.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3086.3230859375008\" x2=\"3086.3230859375008\" y1=\"75.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"105.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 2): </text><rect x=\"10.0\" y=\"155.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 3): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"59.7823046875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.40888671875001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(x_0)</text><rect x=\"79.517734375\" y=\"55.0\" width=\"59.7823046875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.40888671875001\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(x_1)</text><rect x=\"79.517734375\" y=\"105.0\" width=\"59.7823046875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.40888671875001\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(x_2)</text><rect x=\"79.517734375\" y=\"155.0\" width=\"59.7823046875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.40888671875001\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(x_3)</text><rect x=\"159.3000390625\" y=\"5.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"203.48732421875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_0)</text><rect x=\"267.674609375\" y=\"5.0\" width=\"88.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"311.94515624999997\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_1)</text><rect x=\"376.215703125\" y=\"5.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"420.40298828125003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_2)</text><rect x=\"484.59027343749995\" y=\"55.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"528.77755859375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_3)</text><rect x=\"592.96484375\" y=\"55.0\" width=\"88.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"637.235390625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_4)</text><rect x=\"701.5059375\" y=\"55.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"745.69322265625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_5)</text><rect x=\"809.8805078125\" y=\"105.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"854.06779296875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_6)</text><circle cx=\"854.06779296875\" cy=\"25.0\" r=\"10.0\" /><rect x=\"809.8805078125\" y=\"55.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"854.06779296875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"918.2550781250001\" y=\"105.0\" width=\"88.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"962.5256250000001\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_7)</text><rect x=\"1026.796171875\" y=\"105.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1070.98345703125\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_8)</text><rect x=\"1135.1707421875\" y=\"155.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1179.35802734375\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_9)</text><rect x=\"1243.5453125000001\" y=\"155.0\" width=\"97.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1292.2694726562502\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_10)</text><rect x=\"1360.9936328125002\" y=\"155.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1409.6345312500002\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_11)</text><circle cx=\"1498.2754296875003\" cy=\"125.0\" r=\"10.0\" /><rect x=\"1478.2754296875003\" y=\"155.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1498.2754296875003\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1558.2754296875003\" cy=\"75.0\" r=\"10.0\" /><rect x=\"1538.2754296875003\" y=\"105.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1558.2754296875003\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1598.2754296875003\" y=\"5.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1646.9163281250003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_12)</text><rect x=\"1715.5572265625003\" y=\"5.0\" width=\"97.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1764.2813867187504\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_13)</text><rect x=\"1833.0055468750004\" y=\"5.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1881.6464453125004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_14)</text><rect x=\"1950.2873437500004\" y=\"55.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1998.9282421875005\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_15)</text><rect x=\"2067.5691406250003\" y=\"55.0\" width=\"97.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2116.2933007812503\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_16)</text><rect x=\"2185.0174609375003\" y=\"55.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2233.658359375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_17)</text><rect x=\"2302.2992578125004\" y=\"105.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2350.94015625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_18)</text><circle cx=\"2350.94015625\" cy=\"25.0\" r=\"10.0\" /><rect x=\"2302.2992578125004\" y=\"55.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2350.94015625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"2419.5810546875005\" y=\"105.0\" width=\"97.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2468.3052148437505\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_19)</text><rect x=\"2537.0293750000005\" y=\"105.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2585.6702734375003\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_20)</text><rect x=\"2654.3111718750006\" y=\"155.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2702.9520703125004\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_21)</text><rect x=\"2771.5929687500006\" y=\"155.0\" width=\"97.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2820.3171289062507\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_22)</text><rect x=\"2889.0412890625007\" y=\"155.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2937.6821875000005\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_23)</text><circle cx=\"3026.3230859375008\" cy=\"125.0\" r=\"10.0\" /><rect x=\"3006.3230859375008\" y=\"155.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3026.3230859375008\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"3086.3230859375008\" cy=\"75.0\" r=\"10.0\" /><rect x=\"3066.3230859375008\" y=\"105.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3086.3230859375008\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "demo_circuit,i_symbols,p_symbols = pqc_circuit_for_conv(cirq.GridQubit.rect(1,4),layers=2)\n",
        "SVGCircuit(demo_circuit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQa5KS94v3yo"
      },
      "outputs": [],
      "source": [
        "class QConvPQC(tf.keras.layers.Layer):\n",
        "   def __init__(self,n_qubits,layers,name='Quantum Convolutional layer'):\n",
        "     super(QConvPQC,self).__init__(name=name)\n",
        "     self.num_qubits = n_qubits\n",
        "    #  self.symbols = symbols\n",
        "     self.layers = layers\n",
        "     self.main_name = name\n",
        "     self.qubits = cirq.GridQubit.rect(1, n_qubits)\n",
        "     self.observables = cirq.Z(self.qubits[-1])\n",
        "     circuit, input_symbols, param_symbols = pqc_circuit_for_conv(self.qubits,layers=self.layers)\n",
        "     param_vals = tf.random_uniform_initializer(minval=-np.pi,maxval=np.pi)\n",
        "     self.params = tf.Variable(\n",
        "         initial_value=param_vals(shape=(1,len(param_symbols)),dtype='float32'),\n",
        "         trainable = True,\n",
        "         name = self.main_name + '-parameters'\n",
        "     ) \n",
        "     self.empty_circuit = tfq.convert_to_tensor([cirq.Circuit()])\n",
        "\n",
        "     self.computation_layer = tfq.layers.ControlledPQC(circuit, self.observables)\n",
        "    \n",
        "   def get_config(self):\n",
        "     config = super().get_config().copy()\n",
        "     config.update({\n",
        "         'qubit_count':self.num_qubits,\n",
        "        #  'symbols':self.symbols,\n",
        "         'layer_count':self.layers,\n",
        "         'layer_name':self.name\n",
        "     })\n",
        "     return config\n",
        "   def call(self,inputs):\n",
        "     batch_size = tf.shape(inputs)[0]\n",
        "     \n",
        "     inputs_flattened = tf.keras.layers.Flatten()(inputs)\n",
        "     quantum_inputs = tf.math.atan(inputs_flattened)\n",
        "     params_batch = tf.tile(self.params, multiples=[batch_size,1], name=self.main_name + '-tiled_up_parameters')\n",
        "     empty_circuits_batch = tf.repeat(self.empty_circuit, repeats = batch_size, name=self.main_name + '-empty_circuits')\n",
        "     \n",
        "     joined_params = tf.concat([quantum_inputs,params_batch],axis=-1)\n",
        "\n",
        "     return self.computation_layer([empty_circuits_batch,joined_params])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7K_vBLCwBAk"
      },
      "outputs": [],
      "source": [
        "def QConv_layer(inputs,layers,filter_size,stride,conv_id='',name='QConv_layer_'):\n",
        "  iter = int(1 + (inputs.shape[1]-filter_size)/stride)\n",
        "  n_qubits = filter_size*filter_size\n",
        "  pqc = QConvPQC(n_qubits=n_qubits,layers=layers,name=name+conv_id) # \n",
        "  conv = []\n",
        "  for i in range(iter):\n",
        "    for j in range(iter):\n",
        "      temp = pqc(inputs[:,stride*i:filter_size+i*stride,stride*i:filter_size+i*stride])\n",
        "      conv += [temp]\n",
        "  output_concat = tf.keras.layers.Concatenate(axis=1)(conv)\n",
        "  output_reshape = tf.keras.layers.Reshape((iter,iter,1))(output_concat)\n",
        "  return output_reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZmdlVntwET8"
      },
      "outputs": [],
      "source": [
        "layers = 3\n",
        "filter_size = [4,3,2]  \n",
        "stride = [1,1,1]       #for 16x16\n",
        "\n",
        "def create_discriminator_j():\n",
        "  data_inputs = tf.keras.Input(shape=(X_jet.shape[1], X_jet.shape[2],1, ),dtype=tf.dtypes.float32,name='Input_layer')\n",
        "  conv_1 = QConv_layer(inputs=data_inputs,layers=layers,filter_size=filter_size[0],stride=stride[0],conv_id='1') #\n",
        "  conv_2 = QConv_layer(inputs=conv_1,layers=layers,filter_size=filter_size[1],stride=stride[1],conv_id='2')  #\n",
        "  conv_3 = QConv_layer(inputs=conv_2,layers=layers,filter_size=filter_size[2],stride=stride[2],conv_id='3')  #\n",
        "  conv_output = tf.keras.layers.Flatten()(conv_3)\n",
        "  # normalized_conv_output = tf.keras.layers.BatchNormalization(trainable=True)(conv_output)\n",
        "  final_output = tf.keras.layers.Dense(1)(conv_output)\n",
        "  model = tf.keras.Model(inputs=[data_inputs],outputs=[final_output])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3guO4BzlwvJU"
      },
      "outputs": [],
      "source": [
        "def create_classical_discriminator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=[8, 8, 1]))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(16, (2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D(8, (2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hycy8j_wInB",
        "outputId": "39de0c3f-a762-48d7-9b5b-0fcc09aa2c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Input_layer (InputLayer)       [(None, 8, 8, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_5 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_9 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_10 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_11 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_12 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_13 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_14 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_15 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_16 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_17 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_18 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_19 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_20 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_21 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_22 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_23 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_24 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " QConv_layer_1 (QConvPQC)       (None, 1)            144         ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'tf.__operators__.getitem_1[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_3[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_5[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_6[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_7[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_8[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_9[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_10[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_11[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_12[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_13[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_14[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_15[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_16[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_17[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_18[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_19[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_20[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_21[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_22[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_23[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_24[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 25)           0           ['QConv_layer_1[0][0]',          \n",
            "                                                                  'QConv_layer_1[1][0]',          \n",
            "                                                                  'QConv_layer_1[2][0]',          \n",
            "                                                                  'QConv_layer_1[3][0]',          \n",
            "                                                                  'QConv_layer_1[4][0]',          \n",
            "                                                                  'QConv_layer_1[5][0]',          \n",
            "                                                                  'QConv_layer_1[6][0]',          \n",
            "                                                                  'QConv_layer_1[7][0]',          \n",
            "                                                                  'QConv_layer_1[8][0]',          \n",
            "                                                                  'QConv_layer_1[9][0]',          \n",
            "                                                                  'QConv_layer_1[10][0]',         \n",
            "                                                                  'QConv_layer_1[11][0]',         \n",
            "                                                                  'QConv_layer_1[12][0]',         \n",
            "                                                                  'QConv_layer_1[13][0]',         \n",
            "                                                                  'QConv_layer_1[14][0]',         \n",
            "                                                                  'QConv_layer_1[15][0]',         \n",
            "                                                                  'QConv_layer_1[16][0]',         \n",
            "                                                                  'QConv_layer_1[17][0]',         \n",
            "                                                                  'QConv_layer_1[18][0]',         \n",
            "                                                                  'QConv_layer_1[19][0]',         \n",
            "                                                                  'QConv_layer_1[20][0]',         \n",
            "                                                                  'QConv_layer_1[21][0]',         \n",
            "                                                                  'QConv_layer_1[22][0]',         \n",
            "                                                                  'QConv_layer_1[23][0]',         \n",
            "                                                                  'QConv_layer_1[24][0]']         \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 5, 5, 1)      0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_25 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_26 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_27 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_28 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_29 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_30 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_31 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_32 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_33 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " QConv_layer_2 (QConvPQC)       (None, 1)            81          ['tf.__operators__.getitem_25[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_26[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_27[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_28[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_29[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_30[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_31[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_32[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_33[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 9)            0           ['QConv_layer_2[0][0]',          \n",
            "                                                                  'QConv_layer_2[1][0]',          \n",
            "                                                                  'QConv_layer_2[2][0]',          \n",
            "                                                                  'QConv_layer_2[3][0]',          \n",
            "                                                                  'QConv_layer_2[4][0]',          \n",
            "                                                                  'QConv_layer_2[5][0]',          \n",
            "                                                                  'QConv_layer_2[6][0]',          \n",
            "                                                                  'QConv_layer_2[7][0]',          \n",
            "                                                                  'QConv_layer_2[8][0]']          \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 3, 3, 1)      0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_34 (S  (None, 2, 2, 1)     0           ['reshape_1[0][0]']              \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_35 (S  (None, 2, 2, 1)     0           ['reshape_1[0][0]']              \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_36 (S  (None, 2, 2, 1)     0           ['reshape_1[0][0]']              \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_37 (S  (None, 2, 2, 1)     0           ['reshape_1[0][0]']              \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " QConv_layer_3 (QConvPQC)       (None, 1)            36          ['tf.__operators__.getitem_34[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_35[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_36[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_37[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 4)            0           ['QConv_layer_3[0][0]',          \n",
            "                                                                  'QConv_layer_3[1][0]',          \n",
            "                                                                  'QConv_layer_3[2][0]',          \n",
            "                                                                  'QConv_layer_3[3][0]']          \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 2, 2, 1)      0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 4)            0           ['reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            5           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 266\n",
            "Trainable params: 266\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# discriminator_model = create_classical_discriminator()\n",
        "discriminator_model = create_discriminator_j()\n",
        "discriminator_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS3lrMYvwLCS"
      },
      "outputs": [],
      "source": [
        "def get_output_shape(input_shape,filter_shape,stride,padding='same'):\n",
        "  if (input_shape[0] % stride[0] == 0):\n",
        "    pad_along_height = max(filter_shape[0] - stride[0], 0)\n",
        "  else:\n",
        "    pad_along_height = max(filter_shape[0] - (input_shape[0] % stride[0]), 0)\n",
        "  if (input_shape[1] % stride[1] == 0):\n",
        "    pad_along_width = max(filter_shape[1] - stride[1], 0)\n",
        "  else:\n",
        "    pad_along_width = max(filter_shape[1] - (input_shape[1] % stride[1]), 0)\n",
        "  pad_top = pad_along_height // 2\n",
        "  pad_bottom = pad_along_height - pad_top\n",
        "  pad_left = pad_along_width // 2\n",
        "  pad_right = pad_along_width - pad_left\n",
        "  paddings = tf.constant([[pad_top,pad_bottom],[pad_left,pad_right]])\n",
        "  rows = input_shape[0]+paddings[0][0]+paddings[0][1]\n",
        "  cols = input_shape[1]+paddings[1][0]+paddings[1][1]\n",
        "  padded_shape = tf.TensorShape([rows,cols])\n",
        "  new_rows = np.ceil(float(padded_shape[0] - filter_shape[0] + 1) / float(stride[0]))\n",
        "  new_cols = np.ceil(float(padded_shape[1] - filter_shape[1] + 1) / float(stride[1]))\n",
        "  return tf.TensorShape([int(new_rows), int(new_cols)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb5-6zN5wOjn"
      },
      "outputs": [],
      "source": [
        "class QConv2D_layer(tf.keras.layers.Layer):\n",
        "  def __init__(self,layers,filters,filter_shape,stride,seed,parameter_sharing=True,padding='same',conv_id='',name='Quantum_Convolutional_Layer_with_padding'):\n",
        "    super(QConv2D_layer,self).__init__(name=name+conv_id)\n",
        "    self.layers = layers\n",
        "    self.filters = filters\n",
        "    self.parameter_sharing = parameter_sharing\n",
        "    self.filter_shape = filter_shape\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.main_name = name\n",
        "    self.qubits = cirq.GridQubit.rect(1, filter_shape[0]*filter_shape[1])\n",
        "    self.observables = tfq.convert_to_tensor([cirq.Z(self.qubits[-1])])\n",
        "    self.circuit, self.input_symbols, self.param_symbols = pqc_circuit_for_conv(self.qubits,layers=self.layers)\n",
        "    self.model_circuit = tfq.convert_to_tensor([self.circuit])\n",
        "    self.all_symbols = np.concatenate((self.input_symbols,self.param_symbols),axis=0)\n",
        "    self.initializer = tf.keras.initializers.RandomUniform(0, 2 * np.pi, seed=seed)\n",
        "    # self.param_symbols = tf.constant(self.param_symbols)\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    if len(input_shape) == 3:\n",
        "      self.input_rows = input_shape[1]\n",
        "      self.input_cols = input_shape[2]\n",
        "      self.input_channels = 1\n",
        "    else:\n",
        "      self.input_rows = input_shape[1]\n",
        "      self.input_cols = input_shape[2]\n",
        "      self.input_channels = input_shape[3]\n",
        "    output_shape = get_output_shape(input_shape[1:3], self.filter_shape, self.stride, self.padding)\n",
        "    self.output_rows = output_shape[0]\n",
        "    self.output_cols = output_shape[1]\n",
        "    if self.parameter_sharing:\n",
        "      self.kernel_shape = tf.TensorShape([self.filters, self.input_channels, len(self.param_symbols)])\n",
        "    else:\n",
        "      self.kernel_shape = tf.TensorShape([self.filters, self.input_channels, \n",
        "                                               self.output_rows,\n",
        "                                               self.output_cols,\n",
        "                                               len(self.param_symbols)])\n",
        "    self.symbol_names = tfq.util.get_circuit_symbols(tfq.from_tensor(self.model_circuit)[0])\n",
        "    self.kernel = self.add_weight(\n",
        "                        name='kernel',\n",
        "                        shape=self.kernel_shape,\n",
        "                        initializer=self.initializer,\n",
        "                        # regularizer=self.regularizer,\n",
        "                        # constraint=self.constraint,\n",
        "                        trainable=True,\n",
        "                        dtype=self.dtype)\n",
        "    self.inputs_preprocess_ = self.inputs_preprocess()\n",
        "  \n",
        "  def inputs_preprocess(self):\n",
        "      kernel_size = (1, 1) + self.filter_shape + (1,)\n",
        "      strides = (1, 1) + self.stride + (1,)\n",
        "      padding = self.padding.upper()\n",
        "      batchsize = lambda x: tf.gather(tf.shape(x), 0)\n",
        "      # planes = number of channels\n",
        "      planes = self.input_channels\n",
        "      rows = self.input_rows\n",
        "      cols = self.input_cols\n",
        "      depth = 1\n",
        "      reshaped_input_ = lambda x: tf.reshape(x, shape=(batchsize(x), rows, cols, planes))\n",
        "    # change input order to (batchsize, depth, rows, cols)\n",
        "      transposed_input = lambda x: tf.transpose(reshaped_input_(x), [0, 3, 1, 2])\n",
        "      reshaped_input = lambda x: tf.reshape(transposed_input(x), \n",
        "                                              shape=(batchsize(x), planes, rows, cols, depth))\n",
        "      input_patches = lambda x: tf.extract_volume_patches(reshaped_input(x),\n",
        "                                            ksizes=kernel_size, strides=strides, padding=padding)\n",
        "      return input_patches \n",
        "\n",
        "    \n",
        "  def call(self,inputs):\n",
        "    batchsize = tf.gather(tf.shape(inputs), 0)\n",
        "    depth = self.input_channels\n",
        "    rows = self.output_rows\n",
        "    cols = self.output_cols\n",
        "\n",
        "    input_patches = self.inputs_preprocess_(inputs)\n",
        "    # resolved_inputs__ = self._input_resolver(inputs)\n",
        "    inputs = tf.reshape(input_patches, [batchsize, depth, \n",
        "                                      self.output_rows, \n",
        "                                      self.output_cols,\n",
        "                                      len(self.input_symbols)])\n",
        "        # change to (depth, batchsize, rows, cols, symbols)\n",
        "    inputs = tf.transpose(inputs, [1, 0, 2, 3, 4])\n",
        "        # total number of circuit = filters*depth*batchsize*rows*cols\n",
        "    circuit_size = tf.reduce_prod([self.filters, batchsize, depth, rows, cols])\n",
        "        # tile inputs to (filters, depth, batchsize, rows, cols, symbols)\n",
        "    tiled_up_inputs = tf.tile([inputs], [self.filters, 1, 1, 1, 1, 1])\n",
        "        # reshape inputs to (circuit_size, symbols)\n",
        "    tiled_up_inputs = tf.reshape(tiled_up_inputs, (circuit_size, tf.shape(tiled_up_inputs)[-1]))\n",
        "    if self.parameter_sharing:\n",
        "      # tile size for weights = batchsize*rows*cols\n",
        "      tile_size = tf.reduce_prod([batchsize, rows, cols])\n",
        "      tiled_up_weights__ = tf.tile([self.kernel], [tile_size, 1, 1, 1])\n",
        "      # change to (filters, depth, batchsize*rows*cols, weight_symbols)\n",
        "      tiled_up_weights_ = tf.transpose(tiled_up_weights__, [1, 2, 0, 3])\n",
        "    else:\n",
        "      # tile size for weights = batchsize\n",
        "      # weight now has shape (batchsize, filters, depth, rows, cols, weight_symbols)\n",
        "      tiled_up_weights__ = tf.tile([self.kernel], [batchsize, 1, 1, 1, 1, 1])\n",
        "      # change to (filters, depth, batchsize, rows, cols, weight_symbols)\n",
        "      tiled_up_weights_ = tf.transpose(tiled_up_weights__, [1, 2, 0, 3, 4, 5])\n",
        "      # reshape to (circuit_size, weight_symbols)\n",
        "    tiled_up_weights = tf.reshape(tiled_up_weights_, (circuit_size, tf.shape(tiled_up_weights_)[-1]))\n",
        "    tiled_up_parameters = tf.concat([tiled_up_inputs, tiled_up_weights], 1)\n",
        "        \n",
        "    # tiled_up_data_circuit = tf.tile(self._data_circuit, [circuit_size])\n",
        "    tiled_up_circuits = tf.tile(self.model_circuit, [circuit_size])\n",
        "    # model_appended = self._append_layer(tiled_up_data_circuit, append=tiled_up_model)\n",
        "    tiled_up_operators = tf.tile([self.observables], [circuit_size, 1])\n",
        "    \n",
        "    result = tfq.layers.Expectation()(tiled_up_circuits,\n",
        "                                    symbol_names=self.symbol_names,\n",
        "                                    symbol_values=tiled_up_parameters,\n",
        "                                    operators=tiled_up_operators)\n",
        "\n",
        "    reshaped_output = tf.reshape(result,(self.filters, self.input_channels, batchsize, self.output_rows, self.output_cols))\n",
        "    summed_output = tf.reduce_mean(reshaped_output, axis=1)\n",
        "    final_output = tf.transpose(summed_output, [1, 2, 3, 0])\n",
        "    return tf.reshape(final_output, (batchsize, self.output_rows, self.output_cols, self.filters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlBOTongwZKV"
      },
      "outputs": [],
      "source": [
        "def create_generator_j():\n",
        "  model = tf.keras.Sequential(name = 'Generator')\n",
        "  model.add(tf.keras.layers.Input(shape=(64), dtype=tf.float32))\n",
        "  model.add(tf.keras.layers.Reshape((8, 8, 1)))\n",
        "  model.add(QConv2D_layer(layers=1, filter_shape=(3, 3),conv_id ='1',\n",
        "                      filters=2, stride=(1, 1), padding=\"same\", parameter_sharing=False,seed=2021,\n",
        "                      ))\n",
        "  model.add(QConv2D_layer(layers=2, filter_shape=(2, 2),conv_id = '2',\n",
        "                      filters=1, stride=(1, 1), padding=\"same\", parameter_sharing=True,seed=2022,\n",
        "                      ))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM0iSnpsuftz"
      },
      "outputs": [],
      "source": [
        "def create_classical_generator():\n",
        "    model = tf.keras.Sequential()\n",
        "    # foundation for 2x2 image\n",
        "    n_nodes = 64 * 2 * 2\n",
        "    model.add(tf.keras.layers.Dense(n_nodes, use_bias=False, input_shape=(70,)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Reshape((2, 2, 64)))\n",
        "\n",
        "    # model.add(tf.keras.layers.Conv2DTranspose(2, (2,2), strides=(1,1), padding=\"same\", use_bias=False))\n",
        "    # model.add(tf.keras.layers.BatchNormalization())\n",
        "    # model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(32, (2,2), strides=(1,1), padding=\"same\", use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    \n",
        "    # upsample to 4x4\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\", use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())    \n",
        "    # upsample to 8x8\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(1, (3,3), strides=(2,2), padding=\"same\", use_bias=False))   #, activation='tanh'\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0wjP-wLwZ47",
        "outputId": "dc17dc90-d5e3-4c2a-f2d6-4a98184f95a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               17920     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 256)               0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 2, 2, 32)         8192      \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 2, 2, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 2, 2, 32)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 4, 4, 32)         4096      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4, 4, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 8, 8, 1)          288       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,776\n",
            "Trainable params: 31,136\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# generator_model = create_generator_j()\n",
        "generator_model = create_classical_generator()\n",
        "generator_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ERBvUM_bW_5"
      },
      "outputs": [],
      "source": [
        "def create_discriminator_j_improved():\n",
        "  model = tf.keras.Sequential(name = 'Discriminator_Improved')\n",
        "  model.add(tf.keras.Input(shape=(8, 8, 1),dtype=tf.dtypes.float32,name='Input_layer'))\n",
        "  # model.add(tf.keras.layers.Reshape((8, 8, 1)))\n",
        "  model.add(QConv2D_layer(layers=2, filter_shape=(4, 4),conv_id = '1',\n",
        "                      filters=1, stride=(1, 1), padding=\"same\", parameter_sharing=False,seed=2022,\n",
        "                      )) \n",
        "  model.add(QConv2D_layer(layers=3, filter_shape=(3, 3),conv_id ='2',\n",
        "                      filters=2, stride=(2, 2), padding=\"same\", parameter_sharing=False,seed=2021,\n",
        "                      ))\n",
        "  model.add(QConv2D_layer(layers=2, filter_shape=(2, 2),conv_id = '3',\n",
        "                      filters=1, stride=(2, 2), padding=\"same\", parameter_sharing=False,seed=2022,\n",
        "                      )) \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttRuXVd5hXl1",
        "outputId": "2cd67a38-1a34-411c-a6fa-e615019080a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Discriminator_Improved\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Quantum_Convolutional_Layer  (None, 4, 4, 2)          2592      \n",
            " _with_padding2 (QConv2D_lay                                     \n",
            " er)                                                             \n",
            "                                                                 \n",
            " Quantum_Convolutional_Layer  (None, 2, 2, 1)          192       \n",
            " _with_padding3 (QConv2D_lay                                     \n",
            " er)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,789\n",
            "Trainable params: 2,789\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator_model = create_discriminator_j_improved()\n",
        "discriminator_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B13XZu9Ywdiq"
      },
      "outputs": [],
      "source": [
        "class QGAN():\n",
        "  def __init__(self,discriminator,generator,disc_optimizer,gen_optimizer):\n",
        "    self.generator_model = generator\n",
        "    self.discriminator_model = discriminator\n",
        "    self.d_opt = disc_optimizer\n",
        "    self.g_opt = gen_optimizer\n",
        "    # self.g_lr = gen_learning_rate\n",
        "    # self.d_lr = disc_learning_rate\n",
        "    self.loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    self.gen_loss_ = []\n",
        "    self.disc_loss_ = []\n",
        "    self.epochs_ = []\n",
        "    # self.d_opt = self.d_opt(self.d_lr)\n",
        "    # self.g_opt = self.g_opt(self.g_lr)\n",
        "\n",
        "  def prepare_dataset(self,data,batch_size,seed=None,drop_remainder=True,buffer_size=100):\n",
        "    buffer_size =len(data[0])\n",
        "    ds = tf.data.Dataset.from_tensor_slices(data)\n",
        "    ds = ds.shuffle(buffer_size=buffer_size,seed=seed,reshuffle_each_iteration=True)\n",
        "    ds = ds.batch(batch_size,drop_remainder)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "  def train_preprocess(self,random_state):\n",
        "    tf.random.set_seed(random_state)\n",
        "    np.random.seed(random_state)\n",
        "  \n",
        "  @tf.function\n",
        "  def generator_loss(self,fake_output):\n",
        "    # return self.loss(tf.ones_like(fake_output),fake_output)\n",
        "    return -self.loss(tf.zeros_like(fake_output),fake_output)\n",
        "\n",
        "  @tf.function\n",
        "  def discriminator_loss(self,real_output,fake_output):\n",
        "    real_loss = self.loss(tf.ones_like(real_output),real_output)\n",
        "    fake_loss = self.loss(tf.zeros_like(fake_output),fake_output)\n",
        "    return real_loss + fake_loss\n",
        "  \n",
        "  @tf.function\n",
        "  def train_step_1v1(self,x_real,batch_size):\n",
        "    \"\"\"Training step for one epoch with 1 generator step and 1 discriminator step\n",
        "        \"\"\"\n",
        "    fake_data_shape = (batch_size,) + self.generator_model.input_shape[1:]\n",
        "    z = tf.random.normal(shape=fake_data_shape)\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      x_fake_ = self.generator_model(z, training=True)\n",
        "      # x_fake = tf.reshape(x_fake_, tf.shape(x_real))\n",
        "      real_output = self.discriminator_model(x_real, training=True)\n",
        "      fake_output = self.discriminator_model(x_fake_, training=True)\n",
        "      gen_loss = self.generator_loss(fake_output)\n",
        "      disc_loss = self.discriminator_loss(real_output, fake_output)\n",
        "    grad_gen = gen_tape.gradient(gen_loss, self.generator_model.trainable_variables)\n",
        "    grad_disc = disc_tape.gradient(disc_loss, self.discriminator_model.trainable_variables)\n",
        "    self.g_opt.apply_gradients(zip(grad_gen, self.generator_model.trainable_variables))\n",
        "    self.d_opt.apply_gradients(zip(grad_disc, self.discriminator_model.trainable_variables))  \n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "  @tf.function\n",
        "  def train_step_nv1(self,x_real,n_disc,batch_size):\n",
        "    for i in range(n_disc):\n",
        "      x_real_batch = tf.gather(x_real,i)\n",
        "      d_loss = self.discriminator_step(x_real_batch,batch_size)\n",
        "    g_loss = self.generator_step(batch_size)\n",
        "    return g_loss, d_loss\n",
        "\n",
        "  @tf.function\n",
        "  def train_step_1vn(self,x_real,n_gen,batch_size):\n",
        "    for i in range(n_gen):\n",
        "      g_loss = self.generator_step(batch_size)\n",
        "    d_loss = self.discriminator_step(x_real,batch_size)\n",
        "    return g_loss, d_loss \n",
        "\n",
        "  @tf.function\n",
        "  def discriminator_step(self,x_real,batch_size):\n",
        "    fake_data_shape = (batch_size,) + self.generator_model.input_shape[1:]\n",
        "    # x_real = tf.reshape(x_real,fake_data_shape)\n",
        "    z = tf.random.normal(shape=fake_data_shape)\n",
        "    with tf.GradientTape() as gradient_tape:\n",
        "      real_output = self.discriminator_model(x_real,training = True)\n",
        "      fake_input = self.generator_model(z, training = True) \n",
        "      # fake_input = tf.reshape(fake_input, tf.shape(x_real))\n",
        "      fake_output = self.discriminator_model(fake_input,training = True)\n",
        "      cost = self.discriminator_loss(real_output,fake_output)\n",
        "    grad = gradient_tape.gradient(cost,self.discriminator_model.trainable_variables)\n",
        "    self.d_opt.apply_gradients(zip(grad,self.discriminator_model.trainable_variables))\n",
        "    return cost\n",
        "\n",
        "  @tf.function\n",
        "  def generator_step(self,batch_size):\n",
        "    fake_data_shape = (batch_size,) + self.generator_model.input_shape[1:]\n",
        "    z = tf.random.normal(shape=fake_data_shape)\n",
        "    with tf.GradientTape() as gradient_tape:\n",
        "      fake_input = self.generator_model(z,training=True)\n",
        "      fake_output = self.discriminator_model(fake_input,training= True) #\n",
        "      loss = self.generator_loss(fake_output)\n",
        "    grad = gradient_tape.gradient(loss,self.generator_model.trainable_variables)\n",
        "    self.g_opt.apply_gradients(zip(grad,self.generator_model.trainable_variables))\n",
        "    return loss\n",
        "  \n",
        "  def train_qgans(self,x,epochs,batch_size,seed=1024,n_disc=1,n_gen=1):\n",
        "    input_shape = x.shape[1:]\n",
        "    self.train_preprocess(seed)\n",
        "    data = self.prepare_dataset(data=x,batch_size=batch_size*n_disc,seed=seed)\n",
        "    g_metric = tf.keras.metrics.Mean()\n",
        "    d_metric = tf.keras.metrics.Mean()\n",
        "    for epoch in range(epochs):\n",
        "      for step,training_batch_data_ in enumerate(data):\n",
        "        # training_batch_data = tf.reshape(training_batch_data_,input_batch_shape)\n",
        "        if( n_disc == 1 and n_gen == 1):\n",
        "          input_batch_shape = (batch_size,) + input_shape\n",
        "          training_batch_data = tf.reshape(training_batch_data_,input_batch_shape)\n",
        "          gen_loss,disc_loss = self.train_step_1v1(x_real=training_batch_data, batch_size=batch_size)\n",
        "        if n_disc > 1 and n_gen == 1:\n",
        "          input_batch_shape = (n_disc, batch_size) + input_shape\n",
        "          training_batch_data = tf.reshape(training_batch_data_,input_batch_shape)        \n",
        "          gen_loss,disc_loss = self.train_step_nv1(x_real=training_batch_data, batch_size=batch_size,n_disc=n_disc)\n",
        "        if n_gen > 1 and n_disc == 1:\n",
        "          input_batch_shape = (batch_size,) + input_shape\n",
        "          training_batch_data = tf.reshape(training_batch_data_,input_batch_shape)\n",
        "          gen_loss,disc_loss = self.train_step_1vn(x_real=training_batch_data, batch_size=batch_size,n_gen=n_gen)\n",
        "        g_metric(gen_loss)\n",
        "        d_metric(disc_loss)\n",
        "      self.gen_loss_.append(g_metric.result().numpy())\n",
        "      self.disc_loss_.append(d_metric.result().numpy())\n",
        "      self.epochs_.append(epoch)\n",
        "      print(\"Epoch:{} ;   generator_loss:{} ;   discriminator_loss:{}\".format(epoch,g_metric.result().numpy(),d_metric.result().numpy()))\n",
        "  \n",
        "      g_metric.reset_state()\n",
        "      d_metric.reset_state()\n",
        "    return self.gen_loss_,self.disc_loss_,self.epochs_\n",
        "\n",
        "  def generate_samples(self,batch_size, shape=None):\n",
        "    \"\"\"Generates sample using random inputs\n",
        "        \n",
        "            Arguments:\n",
        "                batch_size: int\n",
        "                    Number of samples to generate.\n",
        "                shape: (Optional) tuple of int\n",
        "                    Reshape the output to the given shape.\n",
        "        \"\"\"\n",
        "    z_batch_shape = (batch_size,) + self.generator_model.input_shape[1:]\n",
        "    z = tf.random.normal(z_batch_shape)\n",
        "    print(z.shape[0])\n",
        "    samples = self.generator_model(z,training = False)\n",
        "    # samples = generator_model\n",
        "    # if shape is not None:\n",
        "    #   shape = (batch_size,) + shape\n",
        "    #   samples = tf.reshape(samples, shape)\n",
        "    return samples\n",
        "\n",
        "  def predict(self, x):\n",
        "    return self.discriminator_model(x, training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPTEw3w0wrY4",
        "outputId": "679f8d06-e465-4b58-9c7e-c46dd309603f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 70)\n",
            "(None, 8, 8, 1)\n",
            "(None, 8, 8, 1)\n"
          ]
        }
      ],
      "source": [
        "fake_data_shape = (10000,) + generator_model.input_shape[1:]\n",
        "print(fake_data_shape)\n",
        "print(generator_model.output_shape)\n",
        "print(discriminator_model.input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg1IeTMrwuM2"
      },
      "outputs": [],
      "source": [
        "d_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "g_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "# d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model = QGAN(generator=generator_model,discriminator=discriminator_model,disc_optimizer=d_optimizer,gen_optimizer=g_optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3sOAqwfwx0U",
        "outputId": "a592a172-9922-4569-98d9-a5774a07ca74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 ;   generator_loss:-0.8552355170249939 ;   discriminator_loss:1.436673641204834\n",
            "Epoch:1 ;   generator_loss:-0.8369002938270569 ;   discriminator_loss:1.436746597290039\n",
            "Epoch:2 ;   generator_loss:-0.814459502696991 ;   discriminator_loss:1.4291346073150635\n",
            "Epoch:3 ;   generator_loss:-0.7937597036361694 ;   discriminator_loss:1.4220902919769287\n",
            "Epoch:4 ;   generator_loss:-0.7742529511451721 ;   discriminator_loss:1.416100263595581\n",
            "Epoch:5 ;   generator_loss:-0.7563194036483765 ;   discriminator_loss:1.4111089706420898\n",
            "Epoch:6 ;   generator_loss:-0.7401642799377441 ;   discriminator_loss:1.4071135520935059\n",
            "Epoch:7 ;   generator_loss:-0.7264007329940796 ;   discriminator_loss:1.4039006233215332\n",
            "Epoch:8 ;   generator_loss:-0.7153952717781067 ;   discriminator_loss:1.401129961013794\n",
            "Epoch:9 ;   generator_loss:-0.7083373069763184 ;   discriminator_loss:1.3986567258834839\n",
            "Epoch:10 ;   generator_loss:-0.7031747102737427 ;   discriminator_loss:1.3968474864959717\n",
            "Epoch:11 ;   generator_loss:-0.6996801495552063 ;   discriminator_loss:1.39490807056427\n",
            "Epoch:12 ;   generator_loss:-0.6973176002502441 ;   discriminator_loss:1.3929340839385986\n",
            "Epoch:13 ;   generator_loss:-0.6975687742233276 ;   discriminator_loss:1.3937022686004639\n",
            "Epoch:14 ;   generator_loss:-0.6961315870285034 ;   discriminator_loss:1.3929338455200195\n",
            "Epoch:15 ;   generator_loss:-0.6951566338539124 ;   discriminator_loss:1.3913308382034302\n",
            "Epoch:16 ;   generator_loss:-0.69461989402771 ;   discriminator_loss:1.3900169134140015\n",
            "Epoch:17 ;   generator_loss:-0.6946359872817993 ;   discriminator_loss:1.3891350030899048\n",
            "Epoch:18 ;   generator_loss:-0.694033682346344 ;   discriminator_loss:1.3880236148834229\n",
            "Epoch:19 ;   generator_loss:-0.6941698789596558 ;   discriminator_loss:1.3880661725997925\n",
            "Epoch:20 ;   generator_loss:-0.6956924796104431 ;   discriminator_loss:1.3910572528839111\n",
            "Epoch:21 ;   generator_loss:-0.6950945258140564 ;   discriminator_loss:1.3900887966156006\n",
            "Epoch:22 ;   generator_loss:-0.6941102147102356 ;   discriminator_loss:1.3882635831832886\n",
            "Epoch:23 ;   generator_loss:-0.6934590935707092 ;   discriminator_loss:1.3869831562042236\n",
            "Epoch:24 ;   generator_loss:-0.692882776260376 ;   discriminator_loss:1.3861045837402344\n"
          ]
        }
      ],
      "source": [
        "X_jet_final = np.reshape(X_jet, (X_jet.shape[0], 8, 8, 1))\n",
        "gen_loss_,disc_loss_,epochs_ = model.train_qgans(X_jet,epochs=25,batch_size=180,seed=2021,n_gen=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmsASH4Xw12W"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "def plot_loss(gen_loss,disc_loss,epochs):\n",
        "  fig = plt.figure(figsize=(16,9))\n",
        "  gs = gridspec.GridSpec(ncols=8, nrows=8, figure=fig)\n",
        "  epoch = epochs[-1]\n",
        "  # plot loss curve\n",
        "  ax_loss = plt.subplot(gs[:,:4])\n",
        "  ax_loss.set_xlim(0, 1.1*epoch)\n",
        "  ax_loss.plot(epochs, gen_loss, label=\"Generator\")\n",
        "  ax_loss.plot(epochs, disc_loss, label=\"Discriminator\")\n",
        "  ax_loss.set_xlabel('Epoch', fontsize=20)\n",
        "  ax_loss.set_ylabel('Loss', fontsize=20)\n",
        "  ax_loss.grid(True)\n",
        "  ax_loss.legend(fontsize=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u-cN4Jsw4jr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "595a763c-7e39-4742-b5f4-314b6fe5ea1d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_loss(gen_loss_,disc_loss_,epochs_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wJ3t8xmw-V9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8f799b25-48da-43be-987b-0c64b376bc43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1872x1296 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n_images = 8\n",
        "samples = np.reshape(np.array(model.generate_samples(batch_size=n_images,shape=(5,))),(n_images,8,8))\n",
        "fig = plt.figure(figsize=(26,18))\n",
        "gs = gridspec.GridSpec(ncols=8, nrows=8, figure=fig)\n",
        "for i in range(samples.shape[0]):\n",
        "  ax = plt.subplot(gs[i//4, 4 + i%4])\n",
        "  plt.imshow(samples[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8m78MD0VjJv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}