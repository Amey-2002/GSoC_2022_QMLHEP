{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dYi-RmFsgAp"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow==2.7.0\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAbtbpcUsvVB"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-quantum==0.6.0 --use-deprecated=legacy-resolver\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62UGKVVjtDWZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import sympy as sp\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq\n",
        "from cirq.contrib.svg import SVGCircuit\n",
        "from h5py import File as HDF5File\n",
        "from PIL import Image\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.colors import LogNorm, Normalize\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VVhG-MYtFZW",
        "outputId": "e3423d52-e013-4b86-9b64-0810b578fd07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-58i86ftwRl"
      },
      "outputs": [],
      "source": [
        "jet_mass_datafile = '/content/gdrive/MyDrive//jet-images_Mass60-100_pT250-300_R1.25_Pix25.hdf5'\n",
        "jet_mass_data = HDF5File(jet_mass_datafile, 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aIIZmxTt17C",
        "outputId": "2119f6a8-3a4b-437a-9865-a37e28a8c924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<KeysViewHDF5 ['image', 'jet_delta_R', 'jet_eta', 'jet_mass', 'jet_phi', 'jet_pt', 'signal', 'tau_1', 'tau_2', 'tau_21', 'tau_3', 'tau_32']>\n"
          ]
        }
      ],
      "source": [
        "print(jet_mass_data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "MbmyK6b8t5jP",
        "outputId": "499d4d28-5f51-4a98-ccfb-7013b0631271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(872666, 25, 25)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbd26d6ecd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "X_jet = jet_mass_data['image']\n",
        "print(X_jet.shape)\n",
        "plt.imshow(X_jet[5,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYq0GS8Et5X7",
        "outputId": "09c0aae6-4853-4d2d-be8a-323604d514f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum pixel value for Jet mass images: 312\n",
            "(200, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "max_val_pix = np.argmax(np.mean(X_jet[:, :, :], axis=0))\n",
        "print(\"Maximum pixel value for Jet mass images:\",max_val_pix)\n",
        "center = [int(max_val_pix/25), max_val_pix%25]\n",
        "\n",
        "img_size = 8\n",
        "X_jet = X_jet[:100, (center[0]-int(img_size/2)):(center[0]+int(img_size/2)), (center[1]-int(img_size/2)):(center[1]+int(img_size/2))]\n",
        "\n",
        "print(X_jet.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8uFnSgyuBYo"
      },
      "outputs": [],
      "source": [
        "def plot_jet_image(content,\n",
        "#                     output_name,\n",
        "                    vmin=1e-6,\n",
        "                    vmax=300,\n",
        "                    title=''):\n",
        "    '''\n",
        "    Function to help you visualize a jet image on a log scale\n",
        "    Args:\n",
        "    -----\n",
        "       content : numpy array of dimensions 25x25, first arg to imshow, content of the image\n",
        "                 e.g.: generated_images.mean(axis=0) --> the average generated image\n",
        "                       real_images.mean(axis=0) --> the average Pythia image\n",
        "                       generated_images[aux_out == 1].mean(axis=0) --> the average generated image labeled as real by the discriminator \n",
        "                       etc...\n",
        "       output_name : string, name of the output file where the plot will be saved. Note: it will be located in ../plots/\n",
        "       vmin : (default = 1e-6) float, lower bound of the pixel intensity scale before saturation\n",
        "       vmax : (default = 300) float, upper bound of the pixel intensity scale before saturation\n",
        "       title : (default = '') string, title of the plot, to be displayed on top of the image\n",
        "    Outputs:\n",
        "    --------\n",
        "       no function returns\n",
        "       saves file in ../plots/output_name\n",
        "    '''\n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    extent=[-1.25, 1.25, -1.25, 1.25]\n",
        "    im = ax.imshow(content, interpolation='nearest', norm=LogNorm(vmin=vmin, vmax=vmax), extent=extent)\n",
        "    cbar = plt.colorbar(im, fraction=0.05, pad=0.05)\n",
        "    cbar.set_label(r'Pixel $p_T$ (GeV)', y=0.85)\n",
        "    plt.xlabel(r'[Transformed] Pseudorapidity $(\\eta)$')\n",
        "    plt.ylabel(r'[Transformed] Azimuthal Angle $(\\phi)$')\n",
        "    plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "k_OIGqmfuIBi",
        "outputId": "310a1395-6ab2-432c-dbe2-b994426af4ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbd2005f610>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(X_jet[5,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo_82vRguN9x"
      },
      "outputs": [],
      "source": [
        "def one_qubit_unitary(qubit, symbols):\n",
        "  return cirq.Circuit(\n",
        "    [cirq.rx(symbols[0])(qubit),\n",
        "      cirq.ry(symbols[1])(qubit),\n",
        "      cirq.rz(symbols[2])(qubit)]\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_cd9-s6uSUS"
      },
      "outputs": [],
      "source": [
        "def two_qubit_unitary(qubits):\n",
        "  cx_ops = [cirq.CX(q0, q1) for q0, q1 in zip(qubits, qubits[1:])]\n",
        "  cx_ops += ([cirq.CX(qubits[-1], qubits[0])] if len(qubits) != 2 else [])\n",
        "  return cx_ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keOI1sMMuUy3"
      },
      "outputs": [],
      "source": [
        "def pqc_circuit_for_conv(qubits,layers):\n",
        "  circuit = cirq.Circuit()\n",
        "  num_qubits = len(qubits)\n",
        "  input_symbols = sp.symbols('x_:'+str(num_qubits))\n",
        "  param_symbols = sp.symbols('theta_:'+str(3*num_qubits*layers))\n",
        "  param_symbols = np.reshape(param_symbols,(layers,num_qubits,3))\n",
        "  for i in range(num_qubits):\n",
        "    circuit += cirq.ry(input_symbols[i])(qubits[i])\n",
        "  \n",
        "  for layer in range(layers):\n",
        "    for i,q in enumerate(qubits):\n",
        "      circuit += one_qubit_unitary(q,param_symbols[layer,i,:])\n",
        "    circuit += two_qubit_unitary(qubits)\n",
        "  \n",
        "  return circuit,input_symbols,list(param_symbols.flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "BMD63zltudaL",
        "outputId": "61020785-b101-4fd4-d1e0-7182eaec5857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7fbd20046c50>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"3163.8152734375008\" height=\"200.0\"><line x1=\"34.7588671875\" x2=\"3133.8152734375008\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"3133.8152734375008\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"3133.8152734375008\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"3133.8152734375008\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"856.4091015625\" x2=\"856.4091015625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1182.635859375\" x2=\"1182.635859375\" y1=\"75.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1502.0215234375003\" x2=\"1502.0215234375003\" y1=\"125.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1562.0215234375003\" x2=\"1562.0215234375003\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2357.02755859375\" x2=\"2357.02755859375\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2709.9759960937504\" x2=\"2709.9759960937504\" y1=\"75.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3033.8152734375008\" x2=\"3033.8152734375008\" y1=\"125.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3093.8152734375008\" x2=\"3093.8152734375008\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"105.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 2): </text><rect x=\"10.0\" y=\"155.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 3): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"59.7823046875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.40888671875001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(x_0)</text><rect x=\"79.517734375\" y=\"55.0\" width=\"59.7823046875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.40888671875001\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(x_1)</text><rect x=\"79.517734375\" y=\"105.0\" width=\"59.7823046875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.40888671875001\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(x_2)</text><rect x=\"79.517734375\" y=\"155.0\" width=\"59.7823046875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.40888671875001\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(x_3)</text><rect x=\"159.3000390625\" y=\"5.0\" width=\"89.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"203.9555859375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta_0)</text><rect x=\"268.6111328125\" y=\"5.0\" width=\"88.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"312.88167968749997\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_1)</text><rect x=\"377.1522265625\" y=\"5.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"421.33951171875003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_2)</text><rect x=\"485.52679687499995\" y=\"55.0\" width=\"89.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"530.18234375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta_3)</text><rect x=\"594.837890625\" y=\"55.0\" width=\"88.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"639.1084375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_4)</text><rect x=\"703.378984375\" y=\"55.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"747.56626953125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_5)</text><rect x=\"811.7535546875\" y=\"105.0\" width=\"89.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"856.4091015625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta_6)</text><circle cx=\"856.4091015625\" cy=\"25.0\" r=\"10.0\" /><rect x=\"811.7535546875\" y=\"55.0\" width=\"89.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"856.4091015625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"921.0646484375001\" y=\"105.0\" width=\"88.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"965.3351953125001\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_7)</text><rect x=\"1029.6057421875\" y=\"105.0\" width=\"88.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1073.79302734375\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_8)</text><rect x=\"1137.9803125\" y=\"155.0\" width=\"89.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1182.635859375\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta_9)</text><circle cx=\"1182.635859375\" cy=\"75.0\" r=\"10.0\" /><rect x=\"1137.9803125\" y=\"105.0\" width=\"89.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1182.635859375\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1247.2914062500001\" y=\"155.0\" width=\"97.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1296.0155664062502\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_10)</text><rect x=\"1364.7397265625002\" y=\"155.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1413.3806250000002\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_11)</text><circle cx=\"1502.0215234375003\" cy=\"125.0\" r=\"10.0\" /><rect x=\"1482.0215234375003\" y=\"155.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1502.0215234375003\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1562.0215234375003\" cy=\"175.0\" r=\"10.0\" /><rect x=\"1542.0215234375003\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1562.0215234375003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1602.0215234375003\" y=\"5.0\" width=\"98.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1651.1306835937503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta_12)</text><rect x=\"1720.2398437500003\" y=\"5.0\" width=\"97.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1768.9640039062504\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_13)</text><rect x=\"1837.6881640625004\" y=\"5.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1886.3290625000004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_14)</text><rect x=\"1954.9699609375004\" y=\"55.0\" width=\"98.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2004.0791210937505\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta_15)</text><rect x=\"2073.1882812500003\" y=\"55.0\" width=\"97.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2121.9124414062503\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_16)</text><rect x=\"2190.6366015625003\" y=\"55.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2239.2775\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_17)</text><rect x=\"2307.9183984375004\" y=\"105.0\" width=\"98.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2357.02755859375\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta_18)</text><circle cx=\"2357.02755859375\" cy=\"25.0\" r=\"10.0\" /><rect x=\"2307.9183984375004\" y=\"55.0\" width=\"98.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2357.02755859375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"2426.1367187500005\" y=\"105.0\" width=\"97.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2474.8608789062505\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_19)</text><rect x=\"2543.5850390625005\" y=\"105.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2592.2259375000003\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_20)</text><rect x=\"2660.8668359375006\" y=\"155.0\" width=\"98.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2709.9759960937504\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta_21)</text><circle cx=\"2709.9759960937504\" cy=\"75.0\" r=\"10.0\" /><rect x=\"2660.8668359375006\" y=\"105.0\" width=\"98.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2709.9759960937504\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"2779.0851562500006\" y=\"155.0\" width=\"97.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2827.8093164062507\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta_22)</text><rect x=\"2896.5334765625007\" y=\"155.0\" width=\"97.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2945.1743750000005\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta_23)</text><circle cx=\"3033.8152734375008\" cy=\"125.0\" r=\"10.0\" /><rect x=\"3013.8152734375008\" y=\"155.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3033.8152734375008\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"3093.8152734375008\" cy=\"175.0\" r=\"10.0\" /><rect x=\"3073.8152734375008\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3093.8152734375008\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "demo_circuit,i_symbols,p_symbols = pqc_circuit_for_conv(cirq.GridQubit.rect(1,4),layers=2)\n",
        "SVGCircuit(demo_circuit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQa5KS94v3yo"
      },
      "outputs": [],
      "source": [
        "class QConvPQC(tf.keras.layers.Layer):\n",
        "   def __init__(self,n_qubits,layers,name='Quantum Convolutional layer'):\n",
        "     super(QConvPQC,self).__init__(name=name)\n",
        "     self.num_qubits = n_qubits\n",
        "    #  self.symbols = symbols\n",
        "     self.layers = layers\n",
        "     self.main_name = name\n",
        "     self.qubits = cirq.GridQubit.rect(1, n_qubits)\n",
        "     self.observables = cirq.Z(self.qubits[-1])\n",
        "     circuit, input_symbols, param_symbols = pqc_circuit_for_conv(self.qubits,layers=self.layers)\n",
        "     param_vals = tf.random_uniform_initializer(minval=-np.pi,maxval=np.pi)\n",
        "     self.params = tf.Variable(\n",
        "         initial_value=param_vals(shape=(1,len(param_symbols)),dtype='float32'),\n",
        "         trainable = True,\n",
        "         name = self.main_name + '-parameters'\n",
        "     ) \n",
        "     self.empty_circuit = tfq.convert_to_tensor([cirq.Circuit()])\n",
        "\n",
        "     self.computation_layer = tfq.layers.ControlledPQC(circuit, self.observables)\n",
        "    \n",
        "   def get_config(self):\n",
        "     config = super().get_config().copy()\n",
        "     config.update({\n",
        "         'qubit_count':self.num_qubits,\n",
        "        #  'symbols':self.symbols,\n",
        "         'layer_count':self.layers,\n",
        "         'layer_name':self.name\n",
        "     })\n",
        "     return config\n",
        "   def call(self,inputs):\n",
        "     batch_size = tf.shape(inputs)[0]\n",
        "     \n",
        "     inputs_flattened = tf.keras.layers.Flatten()(inputs)\n",
        "     quantum_inputs = tf.math.atan(inputs_flattened)\n",
        "     params_batch = tf.tile(self.params, multiples=[batch_size,1], name=self.main_name + '-tiled_up_parameters')\n",
        "     empty_circuits_batch = tf.repeat(self.empty_circuit, repeats = batch_size, name=self.main_name + '-empty_circuits')\n",
        "     \n",
        "     joined_params = tf.concat([quantum_inputs,params_batch],axis=-1)\n",
        "\n",
        "     return self.computation_layer([empty_circuits_batch,joined_params])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7K_vBLCwBAk"
      },
      "outputs": [],
      "source": [
        "def QConv_layer(inputs,layers,filter_size,stride,conv_id='',name='QConv_layer_'):\n",
        "  iter = int(1 + (inputs.shape[1]-filter_size)/stride)\n",
        "  n_qubits = filter_size*filter_size\n",
        "  pqc = QConvPQC(n_qubits=n_qubits,layers=layers,name=name+conv_id) # \n",
        "  conv = []\n",
        "  for i in range(iter):\n",
        "    for j in range(iter):\n",
        "      temp = pqc(inputs[:,stride*i:filter_size+i*stride,stride*i:filter_size+i*stride])\n",
        "      conv += [temp]\n",
        "  output_concat = tf.keras.layers.Concatenate(axis=1)(conv)\n",
        "  output_reshape = tf.keras.layers.Reshape((iter,iter,1))(output_concat)\n",
        "  return output_reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZmdlVntwET8"
      },
      "outputs": [],
      "source": [
        "layers = 2\n",
        "filter_size = [4,3,2]  \n",
        "stride = [1,1,1]       #for 16x16\n",
        "\n",
        "def create_discriminator_j():\n",
        "  data_inputs = tf.keras.Input(shape=(X_jet.shape[1], X_jet.shape[2],1, ),dtype=tf.dtypes.float32,name='Input_layer')\n",
        "  conv_1 = QConv_layer(inputs=data_inputs,layers=layers,filter_size=filter_size[0],stride=stride[0],conv_id='1') #\n",
        "  conv_2 = QConv_layer(inputs=conv_1,layers=layers,filter_size=filter_size[1],stride=stride[1],conv_id='2')  #\n",
        "  conv_3 = QConv_layer(inputs=conv_2,layers=layers,filter_size=filter_size[2],stride=stride[2],conv_id='3')  #\n",
        "  conv_output = tf.keras.layers.Flatten()(conv_3)\n",
        "  normalized_conv_output = tf.keras.layers.BatchNormalization(trainable=True)(conv_output)\n",
        "  final_output = tf.keras.layers.Dense(1)(normalized_conv_output)\n",
        "  model = tf.keras.Model(inputs=[data_inputs],outputs=[final_output])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_classical_discriminator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=[8, 8, 1]))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(128, (2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D(64, (2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model"
      ],
      "metadata": {
        "id": "3guO4BzlwvJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hycy8j_wInB",
        "outputId": "6615742c-d55e-4c0c-da4d-07ebad9988b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Input_layer (InputLayer)       [(None, 8, 8, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_5 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_9 (Sl  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_10 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_11 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_12 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_13 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_14 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_15 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_16 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_17 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_18 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_19 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_20 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_21 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_22 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_23 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_24 (S  (None, 4, 4, 1)     0           ['Input_layer[0][0]']            \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " QConv_layer_1 (QConvPQC)       (None, 1)            96          ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'tf.__operators__.getitem_1[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_3[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_5[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_6[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_7[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_8[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_9[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_10[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_11[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_12[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_13[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_14[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_15[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_16[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_17[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_18[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_19[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_20[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_21[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_22[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_23[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_24[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 25)           0           ['QConv_layer_1[0][0]',          \n",
            "                                                                  'QConv_layer_1[1][0]',          \n",
            "                                                                  'QConv_layer_1[2][0]',          \n",
            "                                                                  'QConv_layer_1[3][0]',          \n",
            "                                                                  'QConv_layer_1[4][0]',          \n",
            "                                                                  'QConv_layer_1[5][0]',          \n",
            "                                                                  'QConv_layer_1[6][0]',          \n",
            "                                                                  'QConv_layer_1[7][0]',          \n",
            "                                                                  'QConv_layer_1[8][0]',          \n",
            "                                                                  'QConv_layer_1[9][0]',          \n",
            "                                                                  'QConv_layer_1[10][0]',         \n",
            "                                                                  'QConv_layer_1[11][0]',         \n",
            "                                                                  'QConv_layer_1[12][0]',         \n",
            "                                                                  'QConv_layer_1[13][0]',         \n",
            "                                                                  'QConv_layer_1[14][0]',         \n",
            "                                                                  'QConv_layer_1[15][0]',         \n",
            "                                                                  'QConv_layer_1[16][0]',         \n",
            "                                                                  'QConv_layer_1[17][0]',         \n",
            "                                                                  'QConv_layer_1[18][0]',         \n",
            "                                                                  'QConv_layer_1[19][0]',         \n",
            "                                                                  'QConv_layer_1[20][0]',         \n",
            "                                                                  'QConv_layer_1[21][0]',         \n",
            "                                                                  'QConv_layer_1[22][0]',         \n",
            "                                                                  'QConv_layer_1[23][0]',         \n",
            "                                                                  'QConv_layer_1[24][0]']         \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 5, 5, 1)      0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_25 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_26 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_27 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_28 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_29 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_30 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_31 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_32 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_33 (S  (None, 3, 3, 1)     0           ['reshape[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " QConv_layer_2 (QConvPQC)       (None, 1)            54          ['tf.__operators__.getitem_25[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_26[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_27[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_28[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_29[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_30[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_31[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_32[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_33[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 9)            0           ['QConv_layer_2[0][0]',          \n",
            "                                                                  'QConv_layer_2[1][0]',          \n",
            "                                                                  'QConv_layer_2[2][0]',          \n",
            "                                                                  'QConv_layer_2[3][0]',          \n",
            "                                                                  'QConv_layer_2[4][0]',          \n",
            "                                                                  'QConv_layer_2[5][0]',          \n",
            "                                                                  'QConv_layer_2[6][0]',          \n",
            "                                                                  'QConv_layer_2[7][0]',          \n",
            "                                                                  'QConv_layer_2[8][0]']          \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 3, 3, 1)      0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_34 (S  (None, 2, 2, 1)     0           ['reshape_1[0][0]']              \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_35 (S  (None, 2, 2, 1)     0           ['reshape_1[0][0]']              \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_36 (S  (None, 2, 2, 1)     0           ['reshape_1[0][0]']              \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_37 (S  (None, 2, 2, 1)     0           ['reshape_1[0][0]']              \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " QConv_layer_3 (QConvPQC)       (None, 1)            24          ['tf.__operators__.getitem_34[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_35[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_36[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_37[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 4)            0           ['QConv_layer_3[0][0]',          \n",
            "                                                                  'QConv_layer_3[1][0]',          \n",
            "                                                                  'QConv_layer_3[2][0]',          \n",
            "                                                                  'QConv_layer_3[3][0]']          \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 2, 2, 1)      0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 4)            0           ['reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 4)           16          ['flatten[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            5           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 195\n",
            "Trainable params: 187\n",
            "Non-trainable params: 8\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator_model = create_classical_discriminator()\n",
        "# discriminator_model = create_discriminator_j()\n",
        "discriminator_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS3lrMYvwLCS"
      },
      "outputs": [],
      "source": [
        "def get_output_shape(input_shape,filter_shape,stride,padding='same'):\n",
        "  if (input_shape[0] % stride[0] == 0):\n",
        "    pad_along_height = max(filter_shape[0] - stride[0], 0)\n",
        "  else:\n",
        "    pad_along_height = max(filter_shape[0] - (input_shape[0] % stride[0]), 0)\n",
        "  if (input_shape[1] % stride[1] == 0):\n",
        "    pad_along_width = max(filter_shape[1] - stride[1], 0)\n",
        "  else:\n",
        "    pad_along_width = max(filter_shape[1] - (input_shape[1] % stride[1]), 0)\n",
        "  pad_top = pad_along_height // 2\n",
        "  pad_bottom = pad_along_height - pad_top\n",
        "  pad_left = pad_along_width // 2\n",
        "  pad_right = pad_along_width - pad_left\n",
        "  paddings = tf.constant([[pad_top,pad_bottom],[pad_left,pad_right]])\n",
        "  rows = input_shape[0]+paddings[0][0]+paddings[0][1]\n",
        "  cols = input_shape[1]+paddings[1][0]+paddings[1][1]\n",
        "  padded_shape = tf.TensorShape([rows,cols])\n",
        "  new_rows = np.ceil(float(padded_shape[0] - filter_shape[0] + 1) / float(stride[0]))\n",
        "  new_cols = np.ceil(float(padded_shape[1] - filter_shape[1] + 1) / float(stride[1]))\n",
        "  return tf.TensorShape([int(new_rows), int(new_cols)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb5-6zN5wOjn"
      },
      "outputs": [],
      "source": [
        "class QConv2D_layer(tf.keras.layers.Layer):\n",
        "  def __init__(self,layers,filters,filter_shape,stride,seed,parameter_sharing=True,padding='same',conv_id='',name='Quantum_Convolutional_Layer_with_padding'):\n",
        "    super(QConv2D_layer,self).__init__(name=name+conv_id)\n",
        "    self.layers = layers\n",
        "    self.filters = filters\n",
        "    self.parameter_sharing = parameter_sharing\n",
        "    self.filter_shape = filter_shape\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.main_name = name\n",
        "    self.qubits = cirq.GridQubit.rect(1, filter_shape[0]*filter_shape[1])\n",
        "    self.observables = tfq.convert_to_tensor([cirq.Z(self.qubits[-1])])\n",
        "    self.circuit, self.input_symbols, self.param_symbols = pqc_circuit_for_conv(self.qubits,layers=self.layers)\n",
        "    self.model_circuit = tfq.convert_to_tensor([self.circuit])\n",
        "    self.all_symbols = np.concatenate((self.input_symbols,self.param_symbols),axis=0)\n",
        "    self.initializer = tf.keras.initializers.RandomUniform(0, 2 * np.pi, seed=seed)\n",
        "    # self.param_symbols = tf.constant(self.param_symbols)\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    if len(input_shape) == 3:\n",
        "      self.input_rows = input_shape[1]\n",
        "      self.input_cols = input_shape[2]\n",
        "      self.input_channels = 1\n",
        "    else:\n",
        "      self.input_rows = input_shape[1]\n",
        "      self.input_cols = input_shape[2]\n",
        "      self.input_channels = input_shape[3]\n",
        "    output_shape = get_output_shape(input_shape[1:3], self.filter_shape, self.stride, self.padding)\n",
        "    self.output_rows = output_shape[0]\n",
        "    self.output_cols = output_shape[1]\n",
        "    if self.parameter_sharing:\n",
        "      self.kernel_shape = tf.TensorShape([self.filters, self.input_channels, len(self.param_symbols)])\n",
        "    else:\n",
        "      self.kernel_shape = tf.TensorShape([self.filters, self.input_channels, \n",
        "                                               self.output_rows,\n",
        "                                               self.output_cols,\n",
        "                                               len(self.param_symbols)])\n",
        "    self.symbol_names = tfq.util.get_circuit_symbols(tfq.from_tensor(self.model_circuit)[0])\n",
        "    self.kernel = self.add_weight(\n",
        "                        name='kernel',\n",
        "                        shape=self.kernel_shape,\n",
        "                        initializer=self.initializer,\n",
        "                        # regularizer=self.regularizer,\n",
        "                        # constraint=self.constraint,\n",
        "                        trainable=True,\n",
        "                        dtype=self.dtype)\n",
        "    self.inputs_preprocess_ = self.inputs_preprocess()\n",
        "  \n",
        "  def inputs_preprocess(self):\n",
        "      kernel_size = (1, 1) + self.filter_shape + (1,)\n",
        "      strides = (1, 1) + self.stride + (1,)\n",
        "      padding = self.padding.upper()\n",
        "      batchsize = lambda x: tf.gather(tf.shape(x), 0)\n",
        "      # planes = number of channels\n",
        "      planes = self.input_channels\n",
        "      rows = self.input_rows\n",
        "      cols = self.input_cols\n",
        "      depth = 1\n",
        "      reshaped_input_ = lambda x: tf.reshape(x, shape=(batchsize(x), rows, cols, planes))\n",
        "    # change input order to (batchsize, depth, rows, cols)\n",
        "      transposed_input = lambda x: tf.transpose(reshaped_input_(x), [0, 3, 1, 2])\n",
        "      reshaped_input = lambda x: tf.reshape(transposed_input(x), \n",
        "                                              shape=(batchsize(x), planes, rows, cols, depth))\n",
        "      input_patches = lambda x: tf.extract_volume_patches(reshaped_input(x),\n",
        "                                            ksizes=kernel_size, strides=strides, padding=padding)\n",
        "      return input_patches \n",
        "\n",
        "    \n",
        "  def call(self,inputs):\n",
        "    batchsize = tf.gather(tf.shape(inputs), 0)\n",
        "    depth = self.input_channels\n",
        "    rows = self.output_rows\n",
        "    cols = self.output_cols\n",
        "\n",
        "    input_patches = self.inputs_preprocess_(inputs)\n",
        "    # resolved_inputs__ = self._input_resolver(inputs)\n",
        "    inputs = tf.reshape(input_patches, [batchsize, depth, \n",
        "                                      self.output_rows, \n",
        "                                      self.output_cols,\n",
        "                                      len(self.input_symbols)])\n",
        "        # change to (depth, batchsize, rows, cols, symbols)\n",
        "    inputs = tf.transpose(inputs, [1, 0, 2, 3, 4])\n",
        "        # total number of circuit = filters*depth*batchsize*rows*cols\n",
        "    circuit_size = tf.reduce_prod([self.filters, batchsize, depth, rows, cols])\n",
        "        # tile inputs to (filters, depth, batchsize, rows, cols, symbols)\n",
        "    tiled_up_inputs = tf.tile([inputs], [self.filters, 1, 1, 1, 1, 1])\n",
        "        # reshape inputs to (circuit_size, symbols)\n",
        "    tiled_up_inputs = tf.reshape(tiled_up_inputs, (circuit_size, tf.shape(tiled_up_inputs)[-1]))\n",
        "    if self.parameter_sharing:\n",
        "      # tile size for weights = batchsize*rows*cols\n",
        "      tile_size = tf.reduce_prod([batchsize, rows, cols])\n",
        "      tiled_up_weights__ = tf.tile([self.kernel], [tile_size, 1, 1, 1])\n",
        "      # change to (filters, depth, batchsize*rows*cols, weight_symbols)\n",
        "      tiled_up_weights_ = tf.transpose(tiled_up_weights__, [1, 2, 0, 3])\n",
        "    else:\n",
        "      # tile size for weights = batchsize\n",
        "      # weight now has shape (batchsize, filters, depth, rows, cols, weight_symbols)\n",
        "      tiled_up_weights__ = tf.tile([self.kernel], [batchsize, 1, 1, 1, 1, 1])\n",
        "      # change to (filters, depth, batchsize, rows, cols, weight_symbols)\n",
        "      tiled_up_weights_ = tf.transpose(tiled_up_weights__, [1, 2, 0, 3, 4, 5])\n",
        "      # reshape to (circuit_size, weight_symbols)\n",
        "    tiled_up_weights = tf.reshape(tiled_up_weights_, (circuit_size, tf.shape(tiled_up_weights_)[-1]))\n",
        "    tiled_up_parameters = tf.concat([tiled_up_inputs, tiled_up_weights], 1)\n",
        "        \n",
        "    # tiled_up_data_circuit = tf.tile(self._data_circuit, [circuit_size])\n",
        "    tiled_up_circuits = tf.tile(self.model_circuit, [circuit_size])\n",
        "    # model_appended = self._append_layer(tiled_up_data_circuit, append=tiled_up_model)\n",
        "    tiled_up_operators = tf.tile([self.observables], [circuit_size, 1])\n",
        "    \n",
        "    result = tfq.layers.Expectation()(tiled_up_circuits,\n",
        "                                    symbol_names=self.symbol_names,\n",
        "                                    symbol_values=tiled_up_parameters,\n",
        "                                    operators=tiled_up_operators)\n",
        "\n",
        "    reshaped_output = tf.reshape(result,(self.filters, self.input_channels, batchsize, self.output_rows, self.output_cols))\n",
        "    summed_output = tf.reduce_mean(reshaped_output, axis=1)\n",
        "    final_output = tf.transpose(summed_output, [1, 2, 3, 0])\n",
        "    return tf.reshape(final_output, (batchsize, self.output_rows, self.output_cols, self.filters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlBOTongwZKV"
      },
      "outputs": [],
      "source": [
        "def create_generator_j():\n",
        "  model = tf.keras.Sequential(name = 'Generator')\n",
        "  model.add(tf.keras.layers.Input(shape=(64), dtype=tf.float32))\n",
        "  model.add(tf.keras.layers.Reshape((8, 8, 1)))\n",
        "  model.add(QConv2D_layer(layers=1, filter_shape=(3, 3),conv_id ='1',\n",
        "                      filters=2, stride=(1, 1), padding=\"same\", parameter_sharing=False,seed=2021,\n",
        "                      ))\n",
        "  model.add(QConv2D_layer(layers=2, filter_shape=(2, 2),conv_id = '2',\n",
        "                      filters=1, stride=(1, 1), padding=\"same\", parameter_sharing=True,seed=2022,\n",
        "                      ))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM0iSnpsuftz"
      },
      "outputs": [],
      "source": [
        "def create_classical_generator():\n",
        "    model = tf.keras.Sequential()\n",
        "    # foundation for 2x2 image\n",
        "    n_nodes = 64 * 2 * 2\n",
        "    model.add(tf.keras.layers.Dense(n_nodes, use_bias=False, input_shape=(100,)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Reshape((2, 2, 64)))\n",
        "\n",
        "    # model.add(tf.keras.layers.Conv2DTranspose(2, (2,2), strides=(1,1), padding=\"same\", use_bias=False))\n",
        "    # model.add(tf.keras.layers.BatchNormalization())\n",
        "    # model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    # model.add(tf.keras.layers.Conv2DTranspose(8, (2,2), strides=(2,2), padding=\"same\", use_bias=False))\n",
        "    # model.add(tf.keras.layers.BatchNormalization())\n",
        "    # model.add(tf.keras.layers.LeakyReLU())\n",
        "    \n",
        "    # upsample to 4x4\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(2, (2,2), strides=(2,2), padding=\"same\", use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())    \n",
        "    # upsample to 8x8\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(1, (3,3), strides=(2,2), padding=\"same\", use_bias=False, activation='tanh'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0wjP-wLwZ47",
        "outputId": "72721b7c-8857-47ba-d05f-be4f60219a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 256)               25600     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 256)               0         \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 4, 4, 2)          512       \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4, 4, 2)          8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 4, 4, 2)           0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 8, 8, 1)          18        \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,162\n",
            "Trainable params: 26,646\n",
            "Non-trainable params: 516\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator_model = create_generator_j()\n",
        "# generator_model = create_classical_generator()\n",
        "generator_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B13XZu9Ywdiq"
      },
      "outputs": [],
      "source": [
        "class QGAN():\n",
        "  def __init__(self,discriminator,generator,disc_optimizer,gen_optimizer):\n",
        "    self.generator_model = generator\n",
        "    self.discriminator_model = discriminator\n",
        "    self.d_opt = disc_optimizer\n",
        "    self.g_opt = gen_optimizer\n",
        "    # self.g_lr = gen_learning_rate\n",
        "    # self.d_lr = disc_learning_rate\n",
        "    self.loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    self.gen_loss_ = []\n",
        "    self.disc_loss_ = []\n",
        "    self.epochs_ = []\n",
        "    # self.d_opt = self.d_opt(self.d_lr)\n",
        "    # self.g_opt = self.g_opt(self.g_lr)\n",
        "\n",
        "  def prepare_dataset(self,data,batch_size,seed=None,drop_remainder=True,buffer_size=100):\n",
        "    buffer_size =len(data[0])\n",
        "    ds = tf.data.Dataset.from_tensor_slices(data)\n",
        "    ds = ds.shuffle(buffer_size=buffer_size,seed=seed,reshuffle_each_iteration=True)\n",
        "    ds = ds.batch(batch_size,drop_remainder)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "  def train_preprocess(self,random_state):\n",
        "    tf.random.set_seed(random_state)\n",
        "    np.random.seed(random_state)\n",
        "  \n",
        "  @tf.function\n",
        "  def generator_loss(self,fake_output):\n",
        "    return self.loss(tf.ones_like(fake_output),fake_output)\n",
        "\n",
        "  @tf.function\n",
        "  def discriminator_loss(self,real_output,fake_output):\n",
        "    real_loss = self.loss(tf.ones_like(real_output),real_output)\n",
        "    fake_loss = self.loss(tf.zeros_like(fake_output),fake_output)\n",
        "    return real_loss + fake_loss\n",
        "  \n",
        "  @tf.function\n",
        "  def train_step_1v1(self,x_real,batch_size):\n",
        "    \"\"\"Training step for one epoch with 1 generator step and 1 discriminator step\n",
        "        \"\"\"\n",
        "    fake_data_shape = (batch_size,) + self.generator_model.input_shape[1:]\n",
        "    z = tf.random.normal(shape=fake_data_shape)\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      x_fake_ = self.generator_model(z, training=True)\n",
        "      # x_fake = tf.reshape(x_fake_, tf.shape(x_real))\n",
        "      real_output = self.discriminator_model(x_real, training=True)\n",
        "      fake_output = self.discriminator_model(x_fake_, training=True)\n",
        "      gen_loss = self.generator_loss(fake_output)\n",
        "      disc_loss = self.discriminator_loss(real_output, fake_output)\n",
        "    grad_gen = gen_tape.gradient(gen_loss, self.generator_model.trainable_variables)\n",
        "    grad_disc = disc_tape.gradient(disc_loss, self.discriminator_model.trainable_variables)\n",
        "    self.g_opt.apply_gradients(zip(grad_gen, self.generator_model.trainable_variables))\n",
        "    self.d_opt.apply_gradients(zip(grad_disc, self.discriminator_model.trainable_variables))  \n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "  @tf.function\n",
        "  def train_step_nv1(self,x_real,n_disc,batch_size):\n",
        "    for i in range(n_disc):\n",
        "      x_real_batch = tf.gather(x_real,i)\n",
        "      d_loss = self.discriminator_step(x_real_batch,batch_size)\n",
        "    g_loss = self.generator_step(batch_size)\n",
        "    return g_loss, d_loss\n",
        "\n",
        "  @tf.function\n",
        "  def train_step_1vn(self,x_real,n_gen,batch_size):\n",
        "    for i in range(n_gen):\n",
        "      g_loss = self.generator_step(batch_size)\n",
        "    d_loss = self.discriminator_step(x_real,batch_size)\n",
        "    return g_loss, d_loss \n",
        "\n",
        "  @tf.function\n",
        "  def discriminator_step(self,x_real,batch_size):\n",
        "    fake_data_shape = (batch_size,) + self.generator_model.input_shape[1:]\n",
        "    # x_real = tf.reshape(x_real,fake_data_shape)\n",
        "    z = tf.random.normal(shape=fake_data_shape)\n",
        "    with tf.GradientTape() as gradient_tape:\n",
        "      real_output = self.discriminator_model(x_real,training = True)\n",
        "      fake_input = self.generator_model(z, training = True) \n",
        "      # fake_input = tf.reshape(fake_input, tf.shape(x_real))\n",
        "      fake_output = self.discriminator_model(fake_input,training = True)\n",
        "      cost = self.discriminator_loss(real_output,fake_output)\n",
        "    grad = gradient_tape.gradient(cost,self.discriminator_model.trainable_variables)\n",
        "    self.d_opt.apply_gradients(zip(grad,self.discriminator_model.trainable_variables))\n",
        "    return cost\n",
        "\n",
        "  @tf.function\n",
        "  def generator_step(self,batch_size):\n",
        "    fake_data_shape = (batch_size,) + self.generator_model.input_shape[1:]\n",
        "    z = tf.random.normal(shape=fake_data_shape)\n",
        "    with tf.GradientTape() as gradient_tape:\n",
        "      fake_input = self.generator_model(z,training=True)\n",
        "      fake_output = self.discriminator_model(fake_input,training= True) #\n",
        "      loss = self.generator_loss(fake_output)\n",
        "    grad = gradient_tape.gradient(loss,self.generator_model.trainable_variables)\n",
        "    self.g_opt.apply_gradients(zip(grad,self.generator_model.trainable_variables))\n",
        "    return loss\n",
        "  \n",
        "  def train_qgans(self,x,epochs,batch_size,seed=1024,n_disc=1,n_gen=1):\n",
        "    input_shape = x.shape[1:]\n",
        "    self.train_preprocess(seed)\n",
        "    data = self.prepare_dataset(data=x,batch_size=batch_size*n_disc,seed=seed)\n",
        "    g_metric = tf.keras.metrics.Mean()\n",
        "    d_metric = tf.keras.metrics.Mean()\n",
        "    for epoch in range(epochs):\n",
        "      for step,training_batch_data_ in enumerate(data):\n",
        "        # training_batch_data = tf.reshape(training_batch_data_,input_batch_shape)\n",
        "        if( n_disc == 1 and n_gen == 1):\n",
        "          input_batch_shape = (batch_size,) + input_shape\n",
        "          training_batch_data = tf.reshape(training_batch_data_,input_batch_shape)\n",
        "          gen_loss,disc_loss = self.train_step_1v1(x_real=training_batch_data, batch_size=batch_size)\n",
        "        if n_disc > 1 and n_gen == 1:\n",
        "          input_batch_shape = (n_disc, batch_size) + input_shape\n",
        "          training_batch_data = tf.reshape(training_batch_data_,input_batch_shape)        \n",
        "          gen_loss,disc_loss = self.train_step_nv1(x_real=training_batch_data, batch_size=batch_size,n_disc=n_disc)\n",
        "        if n_gen > 1 and n_disc == 1:\n",
        "          input_batch_shape = (batch_size,) + input_shape\n",
        "          training_batch_data = tf.reshape(training_batch_data_,input_batch_shape)\n",
        "          gen_loss,disc_loss = self.train_step_1vn(x_real=training_batch_data, batch_size=batch_size,n_gen=n_gen)\n",
        "        g_metric(gen_loss)\n",
        "        d_metric(disc_loss)\n",
        "      self.gen_loss_.append(g_metric.result().numpy())\n",
        "      self.disc_loss_.append(d_metric.result().numpy())\n",
        "      self.epochs_.append(epoch)\n",
        "      print(\"Epoch:{} ;   generator_loss:{} ;   discriminator_loss:{}\".format(epoch,g_metric.result().numpy(),d_metric.result().numpy()))\n",
        "  \n",
        "      g_metric.reset_state()\n",
        "      d_metric.reset_state()\n",
        "    return self.gen_loss_,self.disc_loss_,self.epochs_\n",
        "\n",
        "  def generate_samples(self,batch_size, shape=None):\n",
        "    \"\"\"Generates sample using random inputs\n",
        "        \n",
        "            Arguments:\n",
        "                batch_size: int\n",
        "                    Number of samples to generate.\n",
        "                shape: (Optional) tuple of int\n",
        "                    Reshape the output to the given shape.\n",
        "        \"\"\"\n",
        "    z_batch_shape = (batch_size,) + self.generator_model.input_shape[1:]\n",
        "    z = tf.random.normal(z_batch_shape)\n",
        "    print(z.shape[0])\n",
        "    samples = self.generator_model(z,training = False)\n",
        "    # samples = generator_model\n",
        "    # if shape is not None:\n",
        "    #   shape = (batch_size,) + shape\n",
        "    #   samples = tf.reshape(samples, shape)\n",
        "    return samples\n",
        "\n",
        "  def predict(self, x):\n",
        "    return self.discriminator_model(x, training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPTEw3w0wrY4",
        "outputId": "757bd615-5669-416d-df32-352d981a2c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 100)\n",
            "(None, 8, 8, 1)\n",
            "(None, 8, 8, 1)\n"
          ]
        }
      ],
      "source": [
        "fake_data_shape = (10000,) + generator_model.input_shape[1:]\n",
        "print(fake_data_shape)\n",
        "print(generator_model.output_shape)\n",
        "print(discriminator_model.input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg1IeTMrwuM2"
      },
      "outputs": [],
      "source": [
        "# d_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "# g_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.005)\n",
        "d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "model = QGAN(generator=generator_model,discriminator=discriminator_model,disc_optimizer=d_optimizer,gen_optimizer=g_optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3sOAqwfwx0U",
        "outputId": "2bcf0dec-7150-4959-d34b-57cfb4a33299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 ;   generator_loss:0.6930400133132935 ;   discriminator_loss:1.3862942457199097\n",
            "Epoch:1 ;   generator_loss:0.6931341886520386 ;   discriminator_loss:1.3862946033477783\n",
            "Epoch:2 ;   generator_loss:0.6931635141372681 ;   discriminator_loss:1.386293649673462\n",
            "Epoch:3 ;   generator_loss:0.6931421160697937 ;   discriminator_loss:1.386295199394226\n",
            "Epoch:4 ;   generator_loss:0.6931480765342712 ;   discriminator_loss:1.3862948417663574\n",
            "Epoch:5 ;   generator_loss:0.6931479573249817 ;   discriminator_loss:1.3862942457199097\n",
            "Epoch:6 ;   generator_loss:0.693146824836731 ;   discriminator_loss:1.386294960975647\n",
            "Epoch:7 ;   generator_loss:0.693147599697113 ;   discriminator_loss:1.3862950801849365\n",
            "Epoch:8 ;   generator_loss:0.6931480169296265 ;   discriminator_loss:1.386293888092041\n",
            "Epoch:9 ;   generator_loss:0.6931471824645996 ;   discriminator_loss:1.386293888092041\n",
            "Epoch:10 ;   generator_loss:0.693146824836731 ;   discriminator_loss:1.3862950801849365\n",
            "Epoch:11 ;   generator_loss:0.6931459903717041 ;   discriminator_loss:1.3862942457199097\n",
            "Epoch:12 ;   generator_loss:0.6931473016738892 ;   discriminator_loss:1.3862948417663574\n"
          ]
        }
      ],
      "source": [
        "X_jet_final = np.reshape(X_jet, (X_jet.shape[0], 8, 8, 1))\n",
        "gen_loss_,disc_loss_,epochs_ = model.train_qgans(X_jet,epochs=20,batch_size=10,seed=2021,n_disc=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmsASH4Xw12W"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "def plot_loss(gen_loss,disc_loss,epochs):\n",
        "  fig = plt.figure(figsize=(16,9))\n",
        "  gs = gridspec.GridSpec(ncols=8, nrows=8, figure=fig)\n",
        "  epoch = epochs[-1]\n",
        "  # plot loss curve\n",
        "  ax_loss = plt.subplot(gs[:,:4])\n",
        "  ax_loss.set_xlim(0, 1.1*epoch)\n",
        "  ax_loss.plot(epochs, gen_loss, label=\"Generator\")\n",
        "  ax_loss.plot(epochs, disc_loss, label=\"Discriminator\")\n",
        "  ax_loss.set_xlabel('Epoch', fontsize=20)\n",
        "  ax_loss.set_ylabel('Loss', fontsize=20)\n",
        "  ax_loss.grid(True)\n",
        "  ax_loss.legend(fontsize=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u-cN4Jsw4jr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "9d5d0632-053a-4615-f5cf-25143c4666e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_loss(gen_loss_,disc_loss_,epochs_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wJ3t8xmw-V9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dacd5628-a31a-48b2-bcba-476c148f8a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1872x1296 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n_images = 8\n",
        "samples = np.reshape(np.array(model.generate_samples(batch_size=n_images,shape=(5,))),(n_images,8,8))\n",
        "fig = plt.figure(figsize=(26,18))\n",
        "gs = gridspec.GridSpec(ncols=8, nrows=8, figure=fig)\n",
        "for i in range(samples.shape[0]):\n",
        "  ax = plt.subplot(gs[i//4, 4 + i%4])\n",
        "  plt.imshow(samples[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sUMzVdJZ5ZpG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}